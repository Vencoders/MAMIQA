<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <link rel="icon" type="image/x-icon" href="images/YH.png" />
  <title>Project</title>
  <!--Import Google Icon Font-->

  <!--<link href="http://fonts.useso.com/icon?family=Material+Icons" rel="stylesheet">-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="css/main.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <!--Import jQuery before materialize.js-->

  <script type="text/javascript" src="js/jquery-3.0.0.min.js"></script>
  <script type="text/javascript" src="js/materialize.min.js"></script>
  <script type="text/javascript" src="js/main.js"></script>
  <style>
    body
    {
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    }
    .vertical-nav
    {
      margin: 0;
      position: fixed;
      width: 300px;
      /*background-color: #343131;*/
      min-height: 100%;
      background-image: url("images/vertical_oct24.jpg");
      background-repeat: round;
    }

    .profile-block
    {
      position: relative;
      height: 300px;
      /*background-color: #324D5C;*/
    }
    .profile-block-sm
    {
      position: relative;
      height: 200px;
      /*background-color: #324D5C;*/

    }
    .profile-block-tiny
    {
      position: relative;
      height: 50px;
      /*background-color: #324D5C;*/
    }

    .profile
    {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      border-radius: 50%;
      margin-left: 30px;

      border: solid 5px #F4D03F;
    }

    .profile-sm
    {
      /*position: absolute;*/
      /*top: 50%;*/
      /*left: 50%;*/
      /*transform: translateX(50%);*/
      border-radius: 50%;
      margin: auto;

      border: solid 5px #F4D03F;
    }

    .profile-tiny
    {
      position: relative;
      /* top: 50%; */
      transform: translateY(-50%);
      border-radius: 50%;
      margin-left: 20px;

      border: solid 5px #F4D03F;
    }

    .logo-link
    {
      padding-left: 10px;
      padding-right: 10px;
    }
    .card-content
    {
      padding: 0 !important;
      font-size: large
    }

    .card-title
    {
      background-color: #FBD8B0;
      padding: 12px;
    }

    p
    {
      line-height: 150%;
      text-align: justify;
    }
    li
    {
      padding-bottom: 10px;
    }
    strong
    {
      font-weight: bolder;
    }
    .project-item
    {
    }
    .project-logo
    {
    }
  </style>
</head>
<body>
<div class="vertical-nav hide-on-med-and-down">
  <div class="profile-block">
    <img src="images/logo3.png" width="240px" class="profile">
  </div>
  <div style="color: #F8F8f8; font-size: large; margin-top: -30px" class="center-align">
    <p style="" class="center">Vencoders</p>
    <p style="font-size: medium;" class="center">Nanjing University of Information Science and Technology</p>
    <!-- <p style="padding-bottom: 30px; font-size: medium;" class="center"><i class="fa fa-envelope"></i> yyhu AT nyu&middot;edu</p> -->
<!--    <span class="logo-link">
            <a href="https://scholar.google.com/citations?user=MkWer14AAAAJ">
                <img src="images/google-scholar-logo.png" style="width: 30px">
            </a>
        </span>
    <span class="logo-link">
            <a href="https://instagram.com/minoshirod/">
                <img src="images/Instagram.png" style="width: 30px">
            </a>
        </span> -->
    <span class="logo-link">
            <a href="https://github.com/Vencoders">
                <img src="images/GitHub-Mark-Light-120px-plus.png" style="width: 30px">
            </a>
        </span>

<!--    <span class="logo-link">
            <a href="https://www.facebook.com/yueyuhu">
                <img src="images/FB-f-Logo__white_100.png" style="width: 30px">
            </a>
        </span> -->
  </div>

</div>


<div class="hide-on-med-and-down">
  <div style="padding-left: 300px">
    <div class="row" style="">
      <div class="container" style="width: 80%;">
        <div class="row">
          <div class="col s12 m12 l12">
            <div class="card">
              <div class="card-content" style="color: #30505D;">
                <span class="card-title" style="">About Ours</span>
                <p style="padding: 24px; font-size: large;">1.School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China, <br>
									2.Engineering Research Center of Digital Forensics, Ministry of Education, Nanjing University of Information Science and Technology, Nanjing, China.
                  
              </div>
            </div>
          </div>

         
          <div class="col s12 m12 l12">
            <div class="card">
              <div class="card-content" style="color: #30505D;">
                <span class="card-title" style="">Projects</span>
                <div class="project-item">
                  <table>

                    <tr>
                      <td style="width: 30%">
                        <div class="project-logo">
                          <a href="https://vencoders.github.io/natural-transfer.html"><img src="images/frame3.png" style="width: 100%"></a>
                        </div>
                      </td>
                      <td style="width: 70%;">
                        <div class="" >
                          <p style="font-size: 18pt; text-align: left;">
                            Neural texture transfer assisted video coding with adaptive up-sampling
                          </p>
                          <p>
                            A neural texture transfer-assisted video coding with an adaptive up-sampling scheme is proposed in this paper. This scheme adaptively decides whether a frame should be down-sampled or not. In  the decoder, the down-sampled frames are restored by exploring their correlations with the frames that are not down-sampled using neural texture transfer in a multi-scale manner.    
                          </p>
                          <p>
                            <a href="https://vencoders.github.io/natural-transfer">[Project]</a>
							<a href="https://weizequan.github.io/SPIC2022/paper.pdf">[PDF]</a>
							<a href="https://github.com/Vencoders/Ref-frame-encode">[Code]</a>
                          </p>
                        </div>
                      </td>
                    </tr>
					
					
					<tr>
					  <td style="width: 30%">
					    <div class="project-logo">
					      <a href="https://vencoders.github.io/hfcgcnn.html"><img src="images/frame4.png" style="width: 100%"></a>
					    </div>
					  </td>
					  <td style="width: 70%;">
					    <div class="" >
					      <p style="font-size: 18pt; text-align: left;">
					        High-frequency guided CNN for video compression artifacts reduction
					      </p>
					      <p>
					        This paper proposes the HFCG-CNN for video compression artifacts reduction, consisting of high-frequency guidance module and quality enhancement module. The high-frequency guidance module explicitly extracts the high-frequency information in the Y component. Then, the high-frequency information is used in the quality enhancement module to guide the recovery of all Y, U and V components. The experiment results demonstrate the effectiveness of the proposed HFCGCNN method.  
					      </p>
					      <p>
					        <a href="https://vencoders.github.io/hfcgcnn">[Project]</a>
							<a href="https://ieeexplore.ieee.org/abstract/document/10008814/">[PDF]</a>
							<a href="https://github.com/Vencoders/HFCG-CNN">[Code]</a>
					      </p>
					    </div>
					  </td>
					</tr>

          
          <tr>
					  <td style="width: 30%">
					    <div class="project-logo">
					      <a href="https://vencoders.github.io/mamiqa.html"><img src="images/mamiqa1.png" style="width: 100%"></a>
					    </div>
					  </td>
					  <td style="width: 70%;">
					    <div class="" >
					      <p style="font-size: 18pt; text-align: left;">
					        MAMIQA: No-Reference Image Quality Assessment based on Multiscale Attention Mechanism with Natural Scene Statistics
					      </p>
					      <p>
                  No-Reference Image Quality Assessment aims to evaluate the perceptual quality of an image, according to human perception. Many recent studies use Transformers to assign different self-attention mechanisms to distinguish regions of an image, simulating the perception of the human visual system (HVS). However, the quadratic computational complexity caused by the self-attention mechanism is time-consuming and expensive. Meanwhile, the image resizing in the feature extraction stage loses the full-size image quality. To address these issues, we propose a lightweight attention mechanism using decomposed large-kernel convolutions to extract multiscale features, and a novel feature enhancement module to simulate HVS. We also propose to compensate the information loss caused by image resizing, with supplementary features from natural scene statistics. Experimental results on five standard datasets show that the proposed method surpasses the SOTA, while significantly reducing the computational costs.
					      </p>
					      <p>
					        <a href="https://vencoders.github.io/mamiqa">[Project]</a>
							<a href="https://github.com/Vencoders/MAMIQA">[PDF]</a>
							<a href="https://github.com/Vencoders/MAMIQA">[Code]</a>
					      </p>
					    </div>
					  </td>
					</tr>


                  </table>
                </div>

              </div>
            </div>
          </div>


        </div>
      </div>
    </div>
  </div>
</div>


</div>
</body>
</html>
